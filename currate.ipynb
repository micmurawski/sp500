{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pobranie Danych\n",
    "\n",
    "dane zostały poprane ze strony [macrotrends.net](https://www.macrotrends.net/stocks) przy pomocy skryptu `scrape.py` i umieszczone kolejno w folderach `balance-sheet`, `cash-flow-statement`, `financial-ratios`, `income-statement`.\n",
    "Kazdy folder posiada pliki csv z odpowiadającym raportem finansowym dla kazdej z firm indeksu S&P500. Firmy z indeksu S&P zostały pobrane z publicznego repozytrium github - [link](https://github.com/datasets/s-and-p-500-companies/blob/main/data/constituents.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oczyszczanie danych\n",
    "\n",
    "Zbiorcze dane z raportów finansowych (`balance-sheet`, `cash-flow-statement`, `financial-ratios`, `income-statement`) zostały umieszczone w oddzielnych plikach dla danego typu raportu i danej firmy. \n",
    "Dlatego przed przystąpieniem do analizy nalezy dane połączyć do zbiorczych plików CSV które będą zawierać raporty dla wszystkich firm z indeksu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "NOT_INCLUDE = [\n",
    "    'BF.B',\n",
    "    'BRK.B',\n",
    "    'GOOG',\n",
    "    'FOX',\n",
    "    'NWS'\n",
    "]\n",
    "\n",
    "constituents = pd.read_csv('sp500/constituents.csv')\n",
    "\n",
    "constituents['Date added'] = pd.to_datetime(constituents['Date added'])\n",
    "constituents = constituents.loc[~constituents['Symbol'].isin(NOT_INCLUDE)] # remove classes other than A\n",
    "selected_companies = set(constituents['Symbol'].to_list())\n",
    "\n",
    "folders = [\n",
    "    \"financial-ratios\",\n",
    "    \"balance-sheet\",\n",
    "    \"income-statement\",\n",
    "    \"cash-flow-statement\"\n",
    "]\n",
    "\n",
    "df = None\n",
    "\n",
    "for ticker in selected_companies:\n",
    "    all_files_exists = all(\n",
    "        [os.path.isfile(f\"sp500/{folder}/{ticker}.csv\") for folder in folders]\n",
    "    )\n",
    "    if not all_files_exists:\n",
    "        continue\n",
    "\n",
    "    ticker_df = None\n",
    "    \n",
    "    for folder in folders:\n",
    "        file_path = f\"sp500/{folder}/{ticker}.csv\"\n",
    "        new_df = pd.read_csv(file_path)\n",
    "        new_df = new_df.rename(columns={'Unnamed: 0': 'date'})\n",
    "        new_df['date'] = pd.to_datetime(new_df['date'])\n",
    "        new_df.fillna(0, inplace=True)\n",
    "        #new_df = new_df[(new_df['date'].dt.month.eq(12))]\n",
    "        new_df['ticker'] = ticker\n",
    "        \n",
    "        new_df.set_index(['ticker', 'date'], inplace=True)\n",
    "        \n",
    "        if ticker_df is None:\n",
    "            ticker_df = new_df\n",
    "            continue\n",
    "\n",
    "        ticker_df = ticker_df.merge(new_df, left_index=True, right_on=['ticker', 'date'])\n",
    "\n",
    "    if df is None:\n",
    "        df = ticker_df\n",
    "        continue\n",
    "    \n",
    "    df = pd.concat([df, ticker_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def clean_ratio(values):\n",
    "    return np.array([x for x in values if np.isfinite(x) and x > 0])\n",
    "\n",
    "\n",
    "def analyze_pe_percentile(clean_ratios, target_pe):\n",
    "    percentile = np.percentile(clean_ratios, np.linspace(0, 100, 101))\n",
    "    target_percentile = np.interp(target_pe, percentile, np.linspace(0, 100, 101))\n",
    "    \n",
    "    stats = {\n",
    "        'percentile': round(target_percentile, 2),\n",
    "        'larger_than_percent': round(100 - target_percentile, 2),\n",
    "        'median_pe': np.median(clean_ratios),\n",
    "        'mean_pe': np.mean(clean_ratios),\n",
    "        'total_companies': len(clean_ratios),\n",
    "        'summary': f\"P/E ratio of {target_pe:.2f} is larger than {round(target_percentile, 2)}% \"\n",
    "                  f\"of companies in the dataset\"\n",
    "    }\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('sp500/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  498 of 498 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>A</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABNB</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACGL</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>ADI</th>\n",
       "      <th>ADM</th>\n",
       "      <th>...</th>\n",
       "      <th>WY</th>\n",
       "      <th>WYNN</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZTS</th>\n",
       "      <th>^GSPC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-12-01</th>\n",
       "      <td>136.434860</td>\n",
       "      <td>179.868805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157.470001</td>\n",
       "      <td>116.318733</td>\n",
       "      <td>83.289200</td>\n",
       "      <td>368.850586</td>\n",
       "      <td>560.280029</td>\n",
       "      <td>187.735748</td>\n",
       "      <td>51.260288</td>\n",
       "      <td>...</td>\n",
       "      <td>33.377720</td>\n",
       "      <td>104.338028</td>\n",
       "      <td>50.733646</td>\n",
       "      <td>101.902802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.719101</td>\n",
       "      <td>123.330635</td>\n",
       "      <td>279.480011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5096.270020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-01</th>\n",
       "      <td>129.750748</td>\n",
       "      <td>191.556870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144.929993</td>\n",
       "      <td>100.674599</td>\n",
       "      <td>97.590714</td>\n",
       "      <td>278.838379</td>\n",
       "      <td>444.760010</td>\n",
       "      <td>230.578552</td>\n",
       "      <td>60.835281</td>\n",
       "      <td>...</td>\n",
       "      <td>29.278637</td>\n",
       "      <td>94.325630</td>\n",
       "      <td>53.840923</td>\n",
       "      <td>115.386284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.422745</td>\n",
       "      <td>114.424660</td>\n",
       "      <td>312.339996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5277.509766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-01</th>\n",
       "      <td>142.428513</td>\n",
       "      <td>228.483871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117.309998</td>\n",
       "      <td>112.143715</td>\n",
       "      <td>107.537109</td>\n",
       "      <td>339.076752</td>\n",
       "      <td>574.409973</td>\n",
       "      <td>232.010849</td>\n",
       "      <td>59.908264</td>\n",
       "      <td>...</td>\n",
       "      <td>30.102736</td>\n",
       "      <td>76.628067</td>\n",
       "      <td>60.092632</td>\n",
       "      <td>116.998070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.602753</td>\n",
       "      <td>114.948456</td>\n",
       "      <td>345.380005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5648.399902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-01</th>\n",
       "      <td>137.750702</td>\n",
       "      <td>237.069183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.110001</td>\n",
       "      <td>118.212868</td>\n",
       "      <td>95.774498</td>\n",
       "      <td>360.901001</td>\n",
       "      <td>515.929993</td>\n",
       "      <td>216.279999</td>\n",
       "      <td>54.089909</td>\n",
       "      <td>...</td>\n",
       "      <td>32.060555</td>\n",
       "      <td>94.379997</td>\n",
       "      <td>71.937637</td>\n",
       "      <td>117.959999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138.270004</td>\n",
       "      <td>111.851395</td>\n",
       "      <td>407.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6032.379883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>136.460007</td>\n",
       "      <td>253.479996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132.240005</td>\n",
       "      <td>113.290001</td>\n",
       "      <td>90.529999</td>\n",
       "      <td>357.299988</td>\n",
       "      <td>455.230011</td>\n",
       "      <td>212.918472</td>\n",
       "      <td>51.490002</td>\n",
       "      <td>...</td>\n",
       "      <td>29.379999</td>\n",
       "      <td>91.959999</td>\n",
       "      <td>68.080002</td>\n",
       "      <td>108.010002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>134.080292</td>\n",
       "      <td>108.059998</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6050.609863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 499 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker               A        AAPL  ABBV        ABNB         ABT        ACGL  \\\n",
       "Date                                                                           \n",
       "2023-12-01  136.434860  179.868805   NaN  157.470001  116.318733   83.289200   \n",
       "2024-03-01  129.750748  191.556870   NaN  144.929993  100.674599   97.590714   \n",
       "2024-06-01  142.428513  228.483871   NaN  117.309998  112.143715  107.537109   \n",
       "2024-09-01  137.750702  237.069183   NaN  136.110001  118.212868   95.774498   \n",
       "2024-12-01  136.460007  253.479996   NaN  132.240005  113.290001   90.529999   \n",
       "\n",
       "Ticker             ACN        ADBE         ADI        ADM  ...         WY  \\\n",
       "Date                                                       ...              \n",
       "2023-12-01  368.850586  560.280029  187.735748  51.260288  ...  33.377720   \n",
       "2024-03-01  278.838379  444.760010  230.578552  60.835281  ...  29.278637   \n",
       "2024-06-01  339.076752  574.409973  232.010849  59.908264  ...  30.102736   \n",
       "2024-09-01  360.901001  515.929993  216.279999  54.089909  ...  32.060555   \n",
       "2024-12-01  357.299988  455.230011  212.918472  51.490002  ...  29.379999   \n",
       "\n",
       "Ticker            WYNN        XEL         XOM  XYL         YUM         ZBH  \\\n",
       "Date                                                                         \n",
       "2023-12-01  104.338028  50.733646  101.902802  NaN  135.719101  123.330635   \n",
       "2024-03-01   94.325630  53.840923  115.386284  NaN  135.422745  114.424660   \n",
       "2024-06-01   76.628067  60.092632  116.998070  NaN  133.602753  114.948456   \n",
       "2024-09-01   94.379997  71.937637  117.959999  NaN  138.270004  111.851395   \n",
       "2024-12-01   91.959999  68.080002  108.010002  NaN  134.080292  108.059998   \n",
       "\n",
       "Ticker            ZBRA  ZTS        ^GSPC  \n",
       "Date                                      \n",
       "2023-12-01  279.480011  NaN  5096.270020  \n",
       "2024-03-01  312.339996  NaN  5277.509766  \n",
       "2024-06-01  345.380005  NaN  5648.399902  \n",
       "2024-09-01  407.000000  NaN  6032.379883  \n",
       "2024-12-01  395.000000  NaN  6050.609863  \n",
       "\n",
       "[5 rows x 499 columns]"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "start_date = '2009-12-31'\n",
    "end_date = '2024-12-18'\n",
    "ticks = yf.Tickers(list(selected_companies))\n",
    "sp500_close = ticks.history(start=start_date, end=end_date, interval=\"3mo\").Close\n",
    "sp500_close_index = yf.Tickers('^GSPC').history(start=start_date, end=end_date, interval=\"3mo\").Close\n",
    "sp500_close = sp500_close.merge(sp500_close_index, left_index=True, right_on='Date')\n",
    "sp500_close.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_returns(df):\n",
    "    returns_df = df.copy()\n",
    "    returns_df = np.log(df / df.shift(1))\n",
    "    returns_df = returns_df.dropna(how='all')\n",
    "    return returns_df\n",
    "\n",
    "\n",
    "log_returns = pd.melt(\n",
    "    calculate_log_returns(sp500_close).reset_index(),\n",
    "    id_vars=['Date'],\n",
    "    value_vars=list(sp500_close.columns),\n",
    "    var_name='ticker',\n",
    "    value_name='log_return'\n",
    ").rename(columns={\"Date\": 'date'}).set_index(['date', 'ticker']).sort_index()\n",
    "\n",
    "target = pd.melt(\n",
    "    sp500_close.reset_index(),\n",
    "    id_vars=['Date'],\n",
    "    value_vars=list(sp500_close.columns),\n",
    "    var_name='ticker',\n",
    "    value_name='price'\n",
    ").rename(columns={\"Date\": 'date'}).set_index(['date', 'ticker']).sort_index()\n",
    "\n",
    "target['log_return'] = log_returns['log_return']\n",
    "target['class_1'] = (target['log_return'] > 0) * 1\n",
    "\n",
    "for i in range(len(target)):\n",
    "    idx = target.index[i]\n",
    "    spx_idx = (idx[0], '^GSPC')\n",
    "    spx_return = target.at[spx_idx, 'log_return']\n",
    "    stock_return = target.at[idx, 'log_return']\n",
    "    target.at[idx, 'class_2'] = (stock_return > spx_return) * 1\n",
    "\n",
    "target['class_2'] = target['class_2'].astype('int')\n",
    "target.to_csv('sp500/target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
